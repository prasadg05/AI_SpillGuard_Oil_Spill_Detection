{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xG4ym3L4x3Kn",
        "outputId": "1c0213de-111a-4ae8-cab4-bff467ab7671"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'OilSpillDataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3839703562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmasks_dir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/oil_spill_dataset/masks\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOilSpillDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train/val split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OilSpillDataset' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 3. CREATE DATASET AND DATALOADERS\n",
        "# ============================================================\n",
        "\n",
        "images_dir = \"/content/oil_spill_dataset/images\"\n",
        "masks_dir  = \"/content/oil_spill_dataset/masks\"\n",
        "\n",
        "full_dataset = OilSpillDataset(images_dir, masks_dir, img_size=(256, 256), augment=True)\n",
        "\n",
        "# train/val split\n",
        "val_ratio = 0.2\n",
        "val_size = int(len(full_dataset) * val_ratio)\n",
        "train_size = len(full_dataset) - val_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPb0Cl51x8C2"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2. CUSTOM DATASET CLASS FOR OIL SPILL SEGMENTATION\n",
        "# ============================================================\n",
        "class OilSpillDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, img_size=(256, 256), augment=False):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "\n",
        "        self.image_paths = sorted(glob.glob(os.path.join(images_dir, \"*\")))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(masks_dir, \"*\")))\n",
        "        assert len(self.image_paths) == len(self.mask_paths), \"Images & masks count mismatch\"\n",
        "\n",
        "        # basic transforms\n",
        "        self.to_tensor = T.ToTensor()\n",
        "        self.resize_img = T.Resize(img_size, interpolation=T.InterpolationMode.BILINEAR)\n",
        "        self.resize_mask = T.Resize(img_size, interpolation=T.InterpolationMode.NEAREST)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        # load image (RGB)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # grayscale mask (0/255)\n",
        "\n",
        "        # resize\n",
        "        img = self.resize_img(img)\n",
        "        mask = self.resize_mask(mask)\n",
        "\n",
        "        # optional simple augmentation\n",
        "        if self.augment:\n",
        "            if random.random() < 0.5:\n",
        "                img = T.functional.hflip(img)\n",
        "                mask = T.functional.hflip(mask)\n",
        "            if random.random() < 0.5:\n",
        "                img = T.functional.vflip(img)\n",
        "                mask = T.functional.vflip(mask)\n",
        "\n",
        "        img = self.to_tensor(img)          # [3, H, W], float32 in [0,1]\n",
        "        mask = self.to_tensor(mask)        # [1, H, W], float32 in [0,1]\n",
        "        mask = (mask > 0.5).float()        # binarize (0 or 1)\n",
        "\n",
        "        return img, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR1JuM7fyRjO"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 5. METRICS, TRAINING AND VALIDATION FUNCTIONS\n",
        "# ============================================================\n",
        "def compute_iou(preds, targets, threshold=0.5, eps=1e-6):\n",
        "    preds = (preds > threshold).float()\n",
        "    intersection = (preds * targets).sum(dim=(1,2,3))\n",
        "    union = preds.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) - intersection\n",
        "    iou = (intersection + eps) / (union + eps)\n",
        "    return iou.mean().item()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    for imgs, masks in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(logits)\n",
        "            running_iou += compute_iou(probs, masks) * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_iou = running_iou / len(loader.dataset)\n",
        "    return epoch_loss, epoch_iou\n",
        "\n",
        "def validate_one_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, masks)\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            running_iou += compute_iou(probs, masks) * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_iou = running_iou / len(loader.dataset)\n",
        "    return epoch_loss, epoch_iou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mH3q2AiynFb"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 6. TRAINING LOOP\n",
        "# ============================================================\n",
        "num_epochs = 20\n",
        "best_val_iou = 0.0\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_iou = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_iou = validate_one_epoch(model, val_loader, criterion)\n",
        "\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        torch.save(model.state_dict(), \"best_unet_oil_spill.pth\")\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, IoU: {train_iou:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, IoU: {val_iou:.4f}\")\n",
        "\n",
        "print(\"âœ… Training finished. Best Val IoU:\", best_val_iou)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1a-_iA7yq7K"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 7. VISUALIZE PREDICTIONS ON VALIDATION SAMPLE\n",
        "# ============================================================\n",
        "def show_sample_prediction(model, dataset, idx=None):\n",
        "    model.eval()\n",
        "    if idx is None:\n",
        "        idx = random.randint(0, len(dataset)-1)\n",
        "\n",
        "    img, mask = dataset[idx]\n",
        "    with torch.no_grad():\n",
        "        logits = model(img.unsqueeze(0).to(device))\n",
        "        probs = torch.sigmoid(logits)\n",
        "        pred_mask = (probs > 0.5).float().cpu().squeeze(0).squeeze(0).numpy()\n",
        "\n",
        "    img_np = img.permute(1, 2, 0).numpy()\n",
        "    mask_np = mask.squeeze(0).numpy()\n",
        "\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(img_np)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.imshow(mask_np, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title(\"Predicted Mask\")\n",
        "    plt.imshow(pred_mask, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_sample_prediction(model, val_dataset)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
